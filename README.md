# ğŸ§  LLM'S - Memory-Enabled AI Assistant Collection

**A collection of memory-enabled AI assistants that remember conversations using local LLMs**

## ğŸ“¦ Projects

### [Memory LLM](Memory%20LLM/) - Main Package
**Python library for memory-enabled AI assistants**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![PyPI](https://img.shields.io/pypi/v/mem-llm?label=PyPI)](https://pypi.org/project/mem-llm/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

**Memory-enabled AI assistant that remembers user interactions and provides context-aware responses using local LLMs.**

âœ¨ **Key Features:**
- ğŸ§  **Persistent Memory**: Remembers conversations across sessions
- ğŸ’¬ **Context Awareness**: Uses conversation history for relevant responses
- ğŸ  **Local & Private**: Runs entirely on your machine
- ğŸš€ **Lightweight**: Works with small local models (~2.5GB)
- ğŸ¯ **Multi-Backend**: JSON and SQL memory storage options
- ğŸ“š **Knowledge Base**: Config-free document integration
- ğŸŒ **Turkish Support**: Native Turkish language processing

**Quick Start:**
```bash
pip install mem-llm==1.0.7
```

```python
from mem_llm import MemAgent

agent = MemAgent()
agent.set_user("user123")
agent.chat("Hello, my name is Alice")
agent.chat("What's my name?")  # â†’ "Your name is Alice"
```

[ğŸ“– Full Documentation â†’](Memory%20LLM/README.md)

---

## ğŸ¯ What is this?

This repository contains AI assistant projects that add **persistent memory** to local LLM chatbots. Each user gets their own conversation history that the AI remembers across sessions.

**Perfect for:**
- ğŸ’¬ Customer service chatbots
- ğŸ¤– Personal AI assistants
- ğŸ“ Context-aware applications
- ğŸ¢ Business automation

## ğŸš€ Quick Start

### 1. Install Ollama
```bash
# Visit https://ollama.ai/download for installation
ollama serve
```

### 2. Download Model
```bash
ollama pull granite4:tiny-h
```

### 3. Use Memory LLM
```python
from mem_llm import MemAgent

# Create agent (one line!)
agent = MemAgent()

# Set user
agent.set_user("john")

# Chat - it remembers!
agent.chat("My name is John")
agent.chat("What's my name?")  # â†’ "Your name is John"
```

## ğŸ’¡ Features

| Feature | Description |
|---------|-------------|
| ğŸ§  **Memory** | Remembers each user's conversation history |
| ğŸ‘¥ **Multi-user** | Separate memory for each user |
| ğŸ”’ **Privacy** | 100% local, no cloud/API needed |
| âš¡ **Fast** | Lightweight SQLite/JSON storage |
| ğŸ¯ **Simple** | 3 lines of code to get started |
| ğŸ“š **Knowledge Base** | Config-free document integration |
| ğŸŒ **Turkish Support** | Native Turkish language processing |
| ğŸ› ï¸ **Tools** | Extensible tool system for agents |

## ğŸ“š Usage Examples

### Basic Chat
```python
from mem_llm import MemAgent

agent = MemAgent()
agent.set_user("alice")

# First conversation
agent.chat("I love pizza")

# Later...
agent.chat("What's my favorite food?")
# â†’ "Your favorite food is pizza"
```

### Turkish Language Support
```python
# Works seamlessly with Turkish
agent.set_user("ahmet")
agent.chat("Benim adÄ±m Ahmet ve pizza seviyorum")
agent.chat("AdÄ±mÄ± hatÄ±rlÄ±yor musun?")
# â†’ "Tabii ki Ahmet! Sizin pizza sevdiÄŸinizi hatÄ±rlÄ±yorum"
```

### Customer Service Bot
```python
agent = MemAgent()

# Customer 1
agent.set_user("customer_001")
agent.chat("My order #12345 is delayed")

# Customer 2 (different memory!)
agent.set_user("customer_002")
agent.chat("I want to return item #67890")
```

## ğŸ”§ Project Structure

```
LLM'S/
â”œâ”€â”€ Memory LLM/              # Main Python package
â”‚   â”œâ”€â”€ mem_llm/            # Core library
â”‚   â”œâ”€â”€ examples/           # Usage examples
â”‚   â”œâ”€â”€ tests/              # Test suite
â”‚   â”œâ”€â”€ docs/               # Documentation
â”‚   â””â”€â”€ README.md           # Package docs
â”œâ”€â”€ advanced_customer_service.py  # Advanced example
â”œâ”€â”€ company_knowledge.txt        # Knowledge base
â””â”€â”€ README.md               # This file
```

## ğŸ“– Documentation

- **[Memory LLM Documentation](Memory%20LLM/README.md)** - Complete guide for the main package
- **[Examples](Memory%20LLM/examples/)** - Various usage examples
- **[API Reference](Memory%20LLM/README.md#api-reference)** - Detailed API documentation

## ğŸ› ï¸ Development

### Setup Development Environment
```bash
cd "Memory LLM"
pip install -e .
pip install -r requirements.txt
```

### Run Tests
```bash
cd "Memory LLM"
python -m pytest tests/
```

### Build Package
```bash
cd "Memory LLM"
python setup.py sdist bdist_wheel
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

MIT License - See LICENSE file for details.

## ğŸŒŸ Support

- **Issues**: Open an issue for questions or problems
- **Discussions**: Use GitHub Discussions for questions
- **Documentation**: Check the docs folder for detailed guides

---

<div align="center">
Made with â¤ï¸ by <a href="https://github.com/emredeveloper">C. Emre KarataÅŸ</a>
</div>

