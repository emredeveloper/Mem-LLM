# ğŸ§  mem-llm

**Memory-enabled AI assistant that remembers conversations using local LLMs**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![PyPI](https://img.shields.io/pypi/v/mem-llm?label=PyPI)](https://pypi.org/project/mem-llm/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“š Ä°Ã§indekiler

- [ğŸ¯ mem-llm nedir?](#-mem-llm-nedir)
- [âš¡ HÄ±zlÄ± baÅŸlangÄ±Ã§](#-hÄ±zlÄ±-baÅŸlangÄ±Ã§)
- [ğŸ§‘â€ğŸ« Tutorial](#-tutorial)
- [ğŸ’¡ Ã–zellikler](#-Ã¶zellikler)
- [ğŸ“– KullanÄ±m Ã¶rnekleri](#-kullanÄ±m-Ã¶rnekleri)
- [ğŸ”§ YapÄ±landÄ±rma seÃ§enekleri](#-yapÄ±landÄ±rma-seÃ§enekleri)
- [ğŸ—‚ Bilgi tabanÄ± ve dokÃ¼manlardan yapÄ±landÄ±rma](#-bilgi-tabanÄ±-ve-dokÃ¼manlardan-yapÄ±landÄ±rma)
- [ğŸ”¥ Desteklenen modeller](#-desteklenen-modeller)
- [ğŸ“¦ Gereksinimler](#-gereksinimler)
- [ğŸ› SÄ±k karÅŸÄ±laÅŸÄ±lan problemler](#-sÄ±k-karÅŸÄ±laÅŸÄ±lan-problemler)

---

## ğŸ¯ mem-llm nedir?

`mem-llm`, yerel bir LLM ile Ã§alÄ±ÅŸan sohbet botlarÄ±nÄ±za **kalÄ±cÄ± hafÄ±za** kazandÄ±ran hafif bir Python kÃ¼tÃ¼phanesidir. Her kullanÄ±cÄ± iÃ§in ayrÄ± bir konuÅŸma geÃ§miÅŸi tutulur ve yapay zeka bu geÃ§miÅŸi bir sonraki oturumda otomatik olarak kullanÄ±r.

**Nerelerde kullanÄ±labilir?**
- ğŸ’¬ MÃ¼ÅŸteri hizmetleri botlarÄ±
- ğŸ¤– KiÅŸisel asistanlar
- ğŸ“ BaÄŸlama duyarlÄ± uygulamalar
- ğŸ¢ Ä°ÅŸ sÃ¼reÃ§lerini otomatikleÅŸtiren Ã§Ã¶zÃ¼mler

---

## âš¡ HÄ±zlÄ± baÅŸlangÄ±Ã§

### 0. Gereksinimleri kontrol edin

- Python 3.8 veya Ã¼zeri
- [Ollama](https://ollama.ai/) kurulu ve Ã§alÄ±ÅŸÄ±r durumda
- En az 4GB RAM ve 5GB disk alanÄ±

### 1. Paketi yÃ¼kleyin

```bash
pip install mem-llm==1.0.7
```

### 2. Ollama'yÄ± baÅŸlatÄ±n ve modeli indirin (tek seferlik)

```bash
# Ollama servisini baÅŸlatÄ±n
ollama serve

# YaklaÅŸÄ±k 2.5GB'lÄ±k hafif modeli indirin
ollama pull granite4:tiny-h
```

> ğŸ’¡ Ollama `serve` komutu terminalde aÃ§Ä±k kalmalÄ±dÄ±r. Yeni bir terminal sekmesinde Python kodunu Ã§alÄ±ÅŸtÄ±rabilirsiniz.

### 3. Ä°lk ajanÄ±nÄ±zÄ± Ã§alÄ±ÅŸtÄ±rÄ±n

```python
from mem_llm import MemAgent

# Tek satÄ±rda ajan oluÅŸturun
agent = MemAgent()

# KullanÄ±cÄ±yÄ± belirleyin (her kullanÄ±cÄ± iÃ§in ayrÄ± hafÄ±za tutulur)
agent.set_user("john")

# Sohbet edin - hafÄ±za devrede!
agent.chat("My name is John")
agent.chat("What's my name?")  # â†’ "Your name is John"
```

### 4. Kurulumunuzu doÄŸrulayÄ±n (isteÄŸe baÄŸlÄ±)

```python
agent.check_setup()
# {'ollama': 'running', 'model': 'granite4:tiny-h', 'memory_backend': 'sql', ...}
```

<<<<<<< HEAD
| Feature | Description |
|---------|-------------|
| ğŸ§  **Memory** | Remembers each user's conversation history |
| ğŸ‘¥ **Multi-user** | Separate memory for each user |
| ğŸ”’ **Privacy** | 100% local, no cloud/API needed |
| âš¡ **Fast** | Lightweight SQLite/JSON storage |
| ğŸ¯ **Simple** | 3 lines of code to get started |
| ğŸ“š **Knowledge Base** | Config-free document integration |
| ğŸŒ **Multi-language** | Works with any language |
| ğŸ› ï¸ **CLI Tool** | Built-in command-line interface |

---

## ğŸ”„ Memory Backend Comparison

Choose the right backend for your needs:

| Feature | JSON Mode | SQL Mode |
|---------|-----------|----------|
| **Setup** | âœ… Zero config | âš™ï¸ Minimal config |
| **Conversation Memory** | âœ… Yes | âœ… Yes |
| **User Profiles** | âœ… Yes | âœ… Yes |
| **Knowledge Base** | âŒ No | âœ… Yes |
| **Advanced Search** | âŒ No | âœ… Yes |
| **Multi-user Performance** | â­â­ Good | â­â­â­ Excellent |
| **Data Queries** | âŒ Limited | âœ… Full SQL |
| **Best For** | ğŸ  Personal use | ğŸ¢ Business use |

**Recommendation:**
- **JSON Mode**: Perfect for personal assistants and quick prototypes
- **SQL Mode**: Ideal for customer service, multi-user apps, and production
=======
Kurulum sÄ±rasÄ±nda sorun yaÅŸarsanÄ±z [ğŸ› SÄ±k karÅŸÄ±laÅŸÄ±lan problemler](#-sÄ±k-karÅŸÄ±laÅŸÄ±lan-problemler) bÃ¶lÃ¼mÃ¼ne gÃ¶z atÄ±n.
>>>>>>> f002396c8c531e4cde33d19ac6a755494b1b30cd

---

## ğŸ’¡ Ã–zellikler

<<<<<<< HEAD
### Command Line Interface (CLI)

The easiest way to get started:

```bash
# Install with CLI support
pip install mem-llm

# Start interactive chat
mem-llm chat --user john

# Check system status
mem-llm check

# View statistics
mem-llm stats

# Export user data
mem-llm export john --format json --output data.json

# Get help
mem-llm --help
```

**Available CLI Commands:**

| Command | Description | Example |
|---------|-------------|---------|
| `chat` | Interactive chat session | `mem-llm chat --user alice` |
| `check` | Verify system setup | `mem-llm check` |
| `stats` | Show statistics | `mem-llm stats --user john` |
| `export` | Export user data | `mem-llm export john` |
| `clear` | Delete user data | `mem-llm clear john` |

### Basic Chat
=======
| Ã–zellik | AÃ§Ä±klama |
|---------|----------|
| ğŸ§  **KalÄ±cÄ± hafÄ±za** | Her kullanÄ±cÄ±nÄ±n sohbet geÃ§miÅŸi saklanÄ±r |
| ğŸ‘¥ **Ã‡oklu kullanÄ±cÄ±** | Her kullanÄ±cÄ± iÃ§in ayrÄ± hafÄ±za yÃ¶netimi |
| ğŸ”’ **Gizlilik** | Tamamen yerel Ã§alÄ±ÅŸÄ±r, buluta veri gÃ¶ndermez |
| âš¡ **HÄ±zlÄ±** | Hafif SQLite veya JSON depolama seÃ§enekleri |
| ğŸ¯ **Kolay kullanÄ±m** | ÃœÃ§ satÄ±rda Ã§alÄ±ÅŸan Ã¶rnek |
| ğŸ“š **Bilgi tabanÄ±** | Ek yapÄ±landÄ±rma olmadan dÃ¶kÃ¼manlardan bilgi yÃ¼kleme |
| ğŸŒ **TÃ¼rkÃ§e desteÄŸi** | TÃ¼rkÃ§e diyaloglarda doÄŸal sonuÃ§lar |
| ğŸ› ï¸ **AraÃ§ entegrasyonu** | GeliÅŸmiÅŸ araÃ§ sistemi ile geniÅŸletilebilir |

---

## ğŸ§‘â€ğŸ« Tutorial

TamamlanmÄ±ÅŸ Ã¶rnekleri adÄ±m adÄ±m incelemek iÃ§in [examples](examples) klasÃ¶rÃ¼ndeki rehberleri izleyebilirsiniz. Bu dizinde hem temel kullanÄ±m senaryolarÄ± hem de ileri seviye entegrasyonlar yer alÄ±r. Ã–ne Ã§Ä±kan iÃ§erikler:

- [Basic usage walkthrough](examples/basic_usage.py) â€“ ilk hafÄ±zalÄ± ajanÄ±n nasÄ±l oluÅŸturulacaÄŸÄ±nÄ± gÃ¶sterir.
- [Customer support workflow](examples/customer_support.py) â€“ Ã§ok kullanÄ±cÄ±lÄ± mÃ¼ÅŸteri destek senaryosu.
- [Knowledge base ingestion](examples/knowledge_base.py) â€“ dokÃ¼manlardan bilgi yÃ¼kleme.

Her dosyada kodun yanÄ±nda aÃ§Ä±klamalar bulunur; komutlarÄ± kopyalayÄ±p Ã§alÄ±ÅŸtÄ±rarak sonuÃ§larÄ± deneyimleyebilirsiniz.

## ğŸ“– KullanÄ±m Ã¶rnekleri

### Basic conversation
>>>>>>> f002396c8c531e4cde33d19ac6a755494b1b30cd

```python
from mem_llm import MemAgent

agent = MemAgent()
agent.set_user("alice")

# Ä°lk konuÅŸma
agent.chat("I love pizza")

# Later on...
agent.chat("What's my favorite food?")
# â†’ "Your favorite food is pizza"
```

<<<<<<< HEAD
### Multi-language Support

```python
# Works with any language
=======
### Turkish language support

```python
# Handles Turkish dialogue naturally
>>>>>>> f002396c8c531e4cde33d19ac6a755494b1b30cd
agent.set_user("ahmet")
agent.chat("Benim adÄ±m Ahmet ve pizza seviyorum")
agent.chat("AdÄ±mÄ± hatÄ±rlÄ±yor musun?")
# â†’ "Evet, adÄ±nÄ±z Ahmet!"
```

### Customer service scenario

```python
agent = MemAgent()

# MÃ¼ÅŸteri 1
agent.set_user("customer_001")
agent.chat("My order #12345 is delayed")

# Customer 2 (separate memory!)
agent.set_user("customer_002")
agent.chat("I want to return item #67890")
```

### Inspecting the user profile

```python
# Retrieve automatically extracted user information
profile = agent.get_user_profile()
# {'name': 'Alice', 'favorite_food': 'pizza', 'location': 'NYC'}
```

---

## ğŸ”§ YapÄ±landÄ±rma seÃ§enekleri

### JSON hafÄ±za (varsayÄ±lan ve basit)

```python
agent = MemAgent(
    model="granite4:tiny-h",
    use_sql=False,  # JSON dosyalarÄ± ile hafÄ±za
    memory_dir="memories"
)
```

### SQL hafÄ±za (geliÅŸmiÅŸ ve hÄ±zlÄ±)

```python
agent = MemAgent(
    model="granite4:tiny-h",
    use_sql=True,  # SQLite tabanlÄ± hafÄ±za
    memory_dir="memories.db"
)
```

### DiÄŸer Ã¶zelleÅŸtirmeler

```python
agent = MemAgent(
    model="llama2",  # Herhangi bir Ollama modeli
    ollama_url="http://localhost:11434"
)
```

---

## ğŸ“š API referansÄ±

### `MemAgent`

```python
# Initialize
agent = MemAgent(model="granite4:tiny-h", use_sql=False)

# Set active user
agent.set_user(user_id: str, name: Optional[str] = None)

# Chat
response = agent.chat(message: str, metadata: Optional[Dict] = None) -> str

# Get profile
profile = agent.get_user_profile(user_id: Optional[str] = None) -> Dict

# System check
status = agent.check_setup() -> Dict
```

---

## ğŸ—‚ Bilgi tabanÄ± ve dokÃ¼manlardan yapÄ±landÄ±rma

Kurumsal dokÃ¼manlarÄ±nÄ±zdan otomatik `config.yaml` Ã¼retin:

```python
from mem_llm import create_config_from_document

# PDF'den config.yaml Ã¼retin
create_config_from_document(
    doc_path="company_info.pdf",
    output_path="config.yaml",
    company_name="Acme Corp"
)

# OluÅŸan yapÄ±landÄ±rmayÄ± kullanÄ±n
agent = MemAgent(config_file="config.yaml")
```

---

## ğŸ”¥ Desteklenen modeller

[Ollama](https://ollama.ai/) Ã¼zerindeki tÃ¼m modellerle Ã§alÄ±ÅŸÄ±r. Tavsiye edilen modeller:

| Model | Size | Speed | Quality |
|-------|------|-------|---------|
| `granite4:tiny-h` | 2.5GB | âš¡âš¡âš¡ | â­â­ |
| `llama2` | 4GB | âš¡âš¡ | â­â­â­ |
| `mistral` | 4GB | âš¡âš¡ | â­â­â­â­ |
| `llama3` | 5GB | âš¡ | â­â­â­â­â­ |

```bash
ollama pull <model-name>
```

---

## ğŸ“¦ Gereksinimler

- Python 3.8+
- Ollama (LLM iÃ§in)
- Minimum 4GB RAM
- 5GB disk alanÄ±

**Kurulum ile gelen baÄŸÄ±mlÄ±lÄ±klar:**
- `requests >= 2.31.0`
- `pyyaml >= 6.0.1`
- `sqlite3` (Python ile birlikte gelir)

---

## ğŸ› SÄ±k karÅŸÄ±laÅŸÄ±lan problemler

### Ollama Ã§alÄ±ÅŸmÄ±yor mu?

```bash
ollama serve
```

### Model bulunamadÄ± hatasÄ± mÄ± alÄ±yorsunuz?

```bash
ollama pull granite4:tiny-h
```

### ImportError veya baÄŸlantÄ± hatasÄ± mÄ± var?

```bash
pip install --upgrade mem-llm
```

> HÃ¢lÃ¢ sorun yaÅŸÄ±yorsanÄ±z `agent.check_setup()` Ã§Ä±ktÄ±sÄ±nÄ± ve hata mesajÄ±nÄ± issue aÃ§arken paylaÅŸÄ±n.

---

## ğŸ“„ Lisans

MIT LisansÄ± â€” kiÅŸisel veya ticari projelerinizde Ã¶zgÃ¼rce kullanabilirsiniz.

---

## ğŸ”— FaydalÄ± baÄŸlantÄ±lar

- **PyPI:** https://pypi.org/project/mem-llm/
- **GitHub:** https://github.com/emredeveloper/Mem-LLM
- **Ollama:** https://ollama.ai/

---

## ğŸŒŸ Bize destek olun

Proje iÅŸinize yaradÄ±ysa [GitHub](https://github.com/emredeveloper/Mem-LLM) Ã¼zerinden â­ vermeyi unutmayÄ±n!

---

<div align="center">
Sevgiyle geliÅŸtirildi â€” <a href="https://github.com/emredeveloper">C. Emre KarataÅŸ</a>
</div>
